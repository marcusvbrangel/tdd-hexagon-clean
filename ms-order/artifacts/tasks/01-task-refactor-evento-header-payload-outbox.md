
------------------------------------------------------------------------------------------------------------------
TAREFA:


Tarefa (Codex) ‚Äî Refactor do evento order.placed (headers + payload flat) com
Outbox
Objetivo
Refatorar a publica√ß√£o do evento Kafka order.placed para:
1. usar headers oficiais padr√£o (m√≠nimo obrigat√≥rio + recomendados),
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   162/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
2. usar payload flat (DTO de integra√ß√£o v1),
3. manter key = orderId,
4. garantir que o Outbox Pattern continue correto e consistente com essas mudan√ßas,
5. NUNCA ALTERAR NENHUM MODEL DO DOM√çNIO (Order, VOs, Enums etc. s√£o sagrados).
   Parte 1 ‚Äî Por que estamos fazendo isso (contexto pro Codex)
   Headers padronizados tornam rastreabilidade, debug, idempot√™ncia e observabilidade consistentes
   entre micros (padr√£o empresa).
   Payload flat facilita consumo por qualquer linguagem/stack (evita VO { "value": ... } no contrato
   de integra√ß√£o).
   Outbox Pattern precisa refletir exatamente o que vai pro Kafka (payload + headers), sen√£o voc√™ perde
   consist√™ncia e auditabilidade.
   Parte 2 ‚Äî Escopo exato (o que mudar e o que N√ÉO mudar)
   Mudar
   ‚úÖ Apenas camadas de integra√ß√£o/publica√ß√£o:
   adapters de Kafka (producer)
   DTOs de evento (integra√ß√£o)
   mapeamento Domain ‚Üí DTO
   headers builder/helper
   estruturas do outbox se ele armazenar payload/headers
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   163/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   N√ÉO MUDAR
   üö´ NUNCA TOCAR NOS MODELS DO DOM√çNIO
   Nada em domain.model.*
   Nada em Order , OrderId , CustomerId , Money , OrderStatus , etc.
   Nenhuma assinatura p√∫blica do dom√≠nio deve mudar.
   Parte 3 ‚Äî Contrato ‚Äúoficial‚Äù a implementar
   3.1 Topic e Key
   topic: order.placed
   key: orderId (String UUID)
   3.2 Headers oficiais (m√≠nimo obrigat√≥rio)
   Obrigat√≥rios:
   eventId (UUID)
   eventType (ex.: OrderPlaced )
   schemaVersion = "1"
   producer = "order-service"
   occurredAt = ISO-8601 UTC
   correlationId = id do request/saga
   causationId = eventId do evento que causou este (no order.placed , pode ser o pr√≥prio eventId
   anterior do request, ou vazio/igual correlation; defina uma regra consistente)
   Recomendados:
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   164/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   traceparent (se dispon√≠vel)
   contentType = application/json
   Definir nomes de headers (strings) de forma consistente (ex.: x-event-id , x-event-type etc.) OU
   usar exatamente os nomes simples acima ‚Äî mas escolher um padr√£o √∫nico e us√°-lo em todos order.* .
   3.3 Payload oficial (DTO flat v1)
   Para order.placed , o value deve ser:
   json
   {
   "eventId": "...",
   "occurredAt": "...",
   "orderId": "...",
   "customerId": "...",
   "productIds": ["...", "..."]
   }
   Regras:
   Copiar c√≥digo
   orderId e customerId s√£o strings simples.
   productIds √© lista de strings.
   occurredAt deve bater com o header occurredAt (mesmo instante, ou derivado de um √∫nico
   ‚Äúclock/Instant‚Äù gerado 1 vez).
   Parte 4 ‚Äî Estrat√©gia de implementa√ß√£o (passo a passo)
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   165/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Passo 1 ‚Äî Encontrar o ponto atual de publica√ß√£o do order.placed
1. Localizar onde o evento order.placed √© criado e publicado.
2. Identificar:
   como o key √© definido hoje
   quais headers existem hoje (voc√™ j√° tem eventId em header)
   como o payload √© serializado (atualmente com VO {value: ...} )
   Passo 2 ‚Äî Criar DTO de integra√ß√£o flat (sem tocar no dom√≠nio)
1. Criar um DTO novo em camada apropriada, ex.:
   adapter.out.messaging.kafka.dto.OrderPlacedEventV1
   ou application.event.integration.OrderPlacedEventV1
2. Ele deve conter exatamente:
   eventId , occurredAt , orderId , customerId , productIds
   Importante: DTO de integra√ß√£o n√£o √© o model do dom√≠nio.
   Passo 3 ‚Äî Criar um mapper Domain ‚Üí DTO (camada de adapter/out ou application)
1. Criar um mapper claro e test√°vel:
   OrderPlacedEventMapper
2. Input: objetos do dom√≠nio (Order, ids, items)
3. Output: OrderPlacedEventV1 flat
4. O mapper deve:
   extrair orderId.value() como string
   extrair customerId.value() como string
   extrair lista de productIds como strings
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   166/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Passo 4 ‚Äî Implementar ‚ÄúHeader Builder‚Äù oficial (helper √∫nico)
1. Criar uma classe utilit√°ria, ex.:
   adapter.out.messaging.kafka.SagaHeaders (ou EventHeaders )
2. Ela deve:
   gerar eventId
   gerar occurredAt
   preencher eventType=OrderPlaced , schemaVersion=1 , producer=order-service
   aceitar correlationId , causationId , traceparent (quando existir)
   colocar contentType=application/json
3. Garantir que o publisher use esse helper sempre.
   Passo 5 ‚Äî Ajustar o Outbox Pattern para persistir payload+headers novos
   Aqui √© o ponto cr√≠tico.
1. Identificar como sua tabela/outbox entity est√° modelada:
   ela persiste payload como JSON?
   persiste headers ?
   persiste eventType ?
   persiste aggregateId / key ?
2. Ajustar para garantir:
   o outbox armazena o payload flat (JSON)
   o outbox armazena os headers oficiais necess√°rios para reproduzir a mensagem fielmente
   ou, alternativamente: outbox armazena campos estruturados (eventId, occurredAt, correlationId,
   causationId etc.) e monta headers na hora de publicar ‚Äî mas deve ser determin√≠stico e
   reproduz√≠vel.
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   167/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Regra de ouro: o que est√° no outbox √© a fonte da verdade do que vai pro Kafka.
   Se re-gerar eventId/occurredAt na hora de publicar, voc√™ quebra idempot√™ncia e rastreio.
   ‚úÖ Portanto:
   eventId e occurredAt devem ser gerados no momento em que o outbox record √© criado (na
   transa√ß√£o do comando) e persistidos no outbox.
   Passo 6 ‚Äî Ajustar o Outbox Relay/Publisher para publicar com
   key+headers+payload novos
1. Outbox Relay deve:
   ler payload (j√° flat) do outbox
   ler headers (ou campos do outbox) e montar os headers Kafka
   publicar no topic order.placed
   usar key = orderId
2. Garantir que o relay n√£o crie outro eventId/occurredAt ‚Äúnovo‚Äù.
   Passo 7 ‚Äî Atualizar testes (TDD) para travar o contrato
   Criar/atualizar testes em 3 n√≠veis (m√≠nimo recomendado):
   (A) Teste do mapper Domain ‚Üí DTO
   dado Order + itens, o DTO tem:
   orderId string
   customerId string
   productIds flat
   eventId/occurredAt vindo do contexto (ou setado pelo criador)
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   168/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   (B) Teste do Header Builder
   garante presen√ßa de todos headers obrigat√≥rios
   schemaVersion = "1"
   producer = "order-service"
   contentType = "application/json"
   (C) Teste do Outbox Relay
   dado um outbox record com payload+headers persistidos,
   ele publica exatamente 1 mensagem
   com key correta
   com headers corretos
   com value JSON no novo formato
   Se voc√™ tiver testes com Testcontainers + Kafka, √≥timo.
   Sen√£o, use mock do KafkaTemplate/Producer e valide argumentos.
   Parte 5 ‚Äî Decis√µes expl√≠citas que o Codex deve tomar (e
   documentar)
1. Onde fica o DTO flat?
   Sugest√£o: adapter.out.messaging.kafka.dto (porque √© contrato de Kafka)
2. Onde fica o mapper?
   Sugest√£o: adapter.out.messaging.kafka.mapper
3. Como o outbox armazena headers?
   Sugest√£o: campo headersJson (map string->string) + payloadJson
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   169/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
4. Nomes dos headers
   Escolher padr√£o √∫nico (ex.: x-event-id etc.) e usar sempre
   Parte 6 ‚Äî Crit√©rios de aceite (Definition of Done)
   ‚úÖ Quando eu chamar o fluxo que dispara
   order.placed , deve sair no Kafka:
   topic: order.placed
   key: string do orderId
   headers incluem todos obrigat√≥rios:
   eventId, eventType, schemaVersion, producer, occurredAt, correlationId, causationId
   headers incluem recomendados quando poss√≠vel:
   traceparent, contentType=application/json
   value = JSON flat exatamente no contrato v1
   ‚úÖ Outbox Pattern continua consistente:
   eventId/occurredAt n√£o s√£o recriados no relay
   replay do outbox (retry) publica a mesma mensagem (mesmo eventId)
   ‚úÖ Nenhuma classe do
   domain.model foi alterada.
   Parte 7 ‚Äî Instru√ß√µes ‚Äúfortes‚Äù para o Codex (muito importante)
   NUNCA TOCAR NOS MODELS DO DOM√çNIO (qualquer coisa em domain.* √© proibida).
   N√£o alterar assinatura p√∫blica de Order , OrderId , CustomerId etc.
   N√£o mudar regras de neg√≥cio.
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   170/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Qualquer mudan√ßa deve ficar em:
   adapters de Kafka
   DTOs de integra√ß√£o
   mapper
   outbox entity/relay (infra)
   config/serializa√ß√£o
   Parte 8 ‚Äî Entreg√°veis esperados (arquivos prov√°veis)
   adapter/out/messaging/kafka/dto/OrderPlacedEventV1.java
   adapter/out/messaging/kafka/headers/HeaderNames.java
   adapter/out/messaging/kafka/headers/SagaHeaders.java
   adapter/out/messaging/kafka/mapper/OrderPlacedEventMapper.java
   Ajustes em OutboxRelay e/ou OutboxEntity (para armazenar headers/payload)
   Testes:
   OrderPlacedEventMapperTest
   SagaHeadersTest
   OutboxRelayTest (ou equivalente)




-----------------------------------------------

Evento order.placed descri√ß√£o
eventId
eventType
aggregateId (que √© o orderId ‚Üí perfeito para a key)
occurredAt
Ou seja, d√° pra implementar o padr√£o enterprise sem reinventar nada.
1) Problema atual (bem objetivo)
   Hoje o OutboxRelay est√° publicando assim:
   java
   new ProducerRecord<>(msg.getEventType(), msg.getAggregateId(), msg.getPayloadJson())
   Copiar c√≥digo
   Isso significa que:
   topic = eventType (errado: topic deveria ser order.placed , order.confirmed etc.)
   eventType est√° sendo usado como ‚Äúnome do t√≥pico‚Äù
   headers t√™m s√≥ eventId
   payload √© o DomainEvent serializado (VO { "value": ... } )
   Voc√™ quer:
   topic fixo order.placed
   header padr√£o completo
   payload flat v1
   e tudo isso persistido no outbox (pra replay id√™ntico)
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   195/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
2) Mudan√ßa ‚Äúenterprise‚Äù m√≠nima e segura
   Decis√£o chave
   ‚úÖ Separar topic de eventType dentro do Outbox.
   Hoje seu outbox s√≥ tem eventType . Voc√™ precisa adicionar topic (ou destination ), porque:
   eventType = OrderPlaced (tipo l√≥gico da mensagem)
   topic = order.placed (canal Kafka)
   Isso √© padr√£o empresa. N√£o confunda as duas coisas.
3) Refactor pro Outbox (mudan√ßas exatas)
   3.1 Alterar OutboxMessageJpaEntity (sem quebrar o que j√° existe)
   Adicionar:
   topic (String) ‚Üí pra publicar no t√≥pico correto
   headersJson (String @Lob) ‚Üí pra guardar headers oficiais
   Sugest√£o:
   @Column(name="topic", nullable=false, length=128)
   @Lob @Column(name="headers_json", nullable=false)
   Por qu√™ precisa de headersJson se voc√™ j√° tem campos?
   Porque os headers ‚Äúenterprise‚Äù incluem:
   correlationId
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   196/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   causationId
   producer
   schemaVersion
   contentType
   traceparent (quando existir)
   E voc√™ quer que o OutboxRelay n√£o recrie nada.
   ‚úÖ Com
   headersJson , o relay vira ‚Äúdumb‚Äù: l√™ e publica.
   3.2 Alterar OutboxEventPublisherAdapter (ponto onde cria outbox)
   Hoje voc√™ faz:
   serializa o DomainEvent direto ( objectMapper.writeValueAsString(event) )
   salva OutboxMessageJpaEntity(eventId, ..., eventType, payload, occurredAt)
   Agora voc√™ deve fazer:
1. Converter DomainEvent ‚Üí DTO flat v1 (s√≥ para OrderPlacedEvent nessa tarefa)
2. Gerar headers oficiais (Map<String, String>)
3. Persistir no outbox:
   topic = "order.placed"
   eventType = "OrderPlaced"
   payloadJson = JSON do DTO flat
   headersJson = JSON do map de headers
   aggregateId = orderId (continua)
   eventId/occurredAt continuam vindo do DomainEvent (perfeito)
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   197/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Importante: voc√™ j√° tem occurredAt no DomainEvent. Use ele tanto no payload quanto no header. N√£o
   gere Instant.now() diferente.
   E correlationId / causationId?
   Como hoje o EventPublisher.publish(DomainEvent) n√£o recebe contexto, voc√™ tem 3 op√ß√µes:
   Op√ß√£o 1 (m√≠nima agora):
   correlationId = event.eventId() (para order.placed)
   causationId = event.eventId()
   ‚úÖ n√£o √© o ideal, mas √© consistente e n√£o exige mexer em use case.
   Op√ß√£o 2 (boa e ainda simples):
   usar MDC / Sleuth / OTel para pegar correlationId do request (se existir)
   ex.: MDC.get("correlationId")
   ‚úÖ mant√©m assinatura do port, sem tocar dom√≠nio.
   Op√ß√£o 3 (a mais ‚Äúclean‚Äù):
   criar novo port EventPublisherWithContext ou publish(event, context)
   mas a√≠ voc√™ mexe em application layer e em quem chama.
   ‚ö†Ô∏è √© maior.
   üëâ Pra voc√™ n√£o travar agora, eu recomendo Op√ß√£o 2 se voc√™ j√° tiver MDC/OTel, sen√£o Op√ß√£o 1 e depois
   evolui com saga.
   3.3 Alterar OutboxRelay (publicar no t√≥pico certo + headers completos)
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   198/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Hoje:
   topic = msg.getEventType()
   header s√≥ eventId
   Agora:
   topic = msg.getTopic()
   key = msg.getAggregateId() (continua)
   value = msg.getPayloadJson() (agora flat)
   headers: ler headersJson ‚Üí Map<String,String> ‚Üí adicionar em record.headers()
   ‚úÖ E s√≥.
4) O payload flat (onde mapear)
   Voc√™ n√£o toca no dom√≠nio. Voc√™ cria:
   infrastructure.adapter.out.messaging.dto.OrderPlacedEventV1
   com campos:
   eventId
   occurredAt
   orderId
   customerId
   productIds
   E cria um mapper:
   infrastructure.adapter.out.messaging.mapper.OrderPlacedEventMapper
   que pega OrderPlacedEvent (domain.event) e retorna o DTO flat.
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   199/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
5) Headers helper √∫nico (pra n√£o duplicar)
   Voc√™ cria:
   infrastructure.adapter.out.messaging.headers.HeaderNames
   infrastructure.adapter.out.messaging.headers.SagaHeaders
   HeaderNames define as chaves exatas (use exatamente como voc√™ pediu: eventId , eventType , etc. ou
   ent√£o o padr√£o x-* . Como voc√™ escreveu ‚ÄúeventId/eventType‚Äù, vamos manter isso agora.)
   SagaHeaders cria um Map<String,String> pronto para ser serializado.
   Map m√≠nimo obrigat√≥rio + recomendados:
   eventId
   eventType
   schemaVersion = "1"
   producer = "order-service"
   occurredAt = same Instant do event
   correlationId (ver op√ß√µes acima)
   causationId
   contentType = "application/json"
   traceparent (se tiver)
6) Ajuste extra importante: voc√™ est√° usando eventType como topic
   Voc√™ vai corrigir isso nessa tarefa.
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   200/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
   Regra oficial:
   topic = "order.placed" (fixo)
   header eventType = "OrderPlaced"
   Ou seja, seu Outbox passa a ter os dois:
   topic
   eventType
7) Tarefa pronta pro Codex (atualizada com seus arquivos reais)
   Cole no Codex CLI:
   text
   REFATOR (ms-order): Padronizar publica√ß√£o do evento Kafka order.placed (headers oficiais +
   RESTRI√á√ÉO ABSOLUTA:
- NUNCA alterar nada em com.mvbr.retailstore.order.domain.model.*
- NUNCA alterar regras do Aggregate Order/VOs/Enums.
- Domain events podem existir como est√£o; integra√ß√£o ser√° feita fora do dom√≠nio.
  SITUA√á√ÉO ATUAL:
- OutboxMessageJpaEntity tem eventId, aggregateId (orderId), eventType, payloadJson, occur
- OutboxEventPublisherAdapter serializa DomainEvent direto e grava no outbox.
- OutboxRelay publica em Kafka usando msg.getEventType() como TOPIC, e adiciona apenas hea
  OBJETIVO:
1) Publicar no topic fixo: "order.placed"
   https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
   201/20519/12/2025, 17:56
   Evento order.placed descri√ß√£o
2) Key SEMPRE: msg.getAggregateId() (orderId)
3) Headers oficiais no Kafka (m√≠nimo obrigat√≥rio):
- eventId, eventType (OrderPlaced), schemaVersion("1"), producer("order-service"),
  occurredAt (ISO-8601 UTC), correlationId, causationId
  Recomendados:
- traceparent (se dispon√≠vel), contentType("application/json")
4) Payload deve ser DTO flat v1 (n√£o serializar VOs como {"value":...}):
   {
   "eventId": "...",
   "occurredAt": "...",
   "orderId": "...",
   "customerId": "...",
   "productIds": ["...","..."]
   }
5) Outbox Pattern: eventId/occurredAt/correlationId/causationId + payload flat DEVEM ser p
   MUDAN√áAS NECESS√ÅRIAS (arquivos reais):
   A) Criar helper de headers:
- com.mvbr.retailstore.order.infrastructure.adapter.out.messaging.headers.HeaderNames (con
- com.mvbr.retailstore.order.infrastructure.adapter.out.messaging.headers.SagaHeaders (bui
  B) Criar DTO e mapper:
- com.mvbr.retailstore.order.infrastructure.adapter.out.messaging.dto.OrderPlacedEventV1
- com.mvbr.retailstore.order.infrastructure.adapter.out.messaging.mapper.OrderPlacedEventM
  C) Ajustar OutboxMessageJpaEntity:
- adicionar coluna/topic: String topic (nullable=false)
- adicionar LOB headersJson: String headersJson (nullable=false)
- manter eventType como "OrderPlaced" (tipo l√≥gico), e topic como "order.placed" (destino
  https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
  202/20519/12/2025, 17:56
  Evento order.placed descri√ß√£o
  D) Ajustar OutboxEventPublisherAdapter:
- ao receber DomainEvent do tipo OrderPlacedEvent:
- mapear para OrderPlacedEventV1 (flat)
- gerar headers Map via SagaHeaders com:
  eventId=event.eventId, eventType="OrderPlaced", occurredAt=event.occurredAt,
  schemaVersion="1", producer="order-service",
  correlationId (preferir MDC/trace se existir, sen√£o fallback),
  causationId (para order.placed usar correlationId ou eventId, mas ser consistente),
  contentType="application/json", traceparent se dispon√≠vel
- serializar payload flat para payloadJson
- serializar headers map para headersJson
- persistir OutboxMessageJpaEntity com topic="order.placed"
- manter suporte a outros eventos (confirmed/canceled) sem mudar contrato deles ainda (n√£o
  E) Ajustar OutboxRelay:
- publicar ProducerRecord com:
  topic = msg.getTopic()
  key = msg.getAggregateId()
  value = msg.getPayloadJson()
- adicionar TODOS headers vindos de msg.getHeadersJson() (parse JSON para Map e add em rec
- N√ÉO criar eventId/occurredAt novos.
  TESTES (m√≠nimo):
- Teste do OrderPlacedEventMapper (gera DTO flat correto)
- Teste do SagaHeaders (gera mapa com chaves obrigat√≥rias)
- Teste do OutboxRelay: dado msg com headersJson+payloadJson, publica record com topic cor
  CRIT√âRIO DE ACEITE:
  https://chatgpt.com/c/69459e78-a240-8331-8a9d-747d572a96c6
  203/20519/12/2025, 17:56
  Evento order.placed descri√ß√£o
- Mensagem no Kafka em topic "order.placed" com key=orderId
- Headers obrigat√≥rios presentes
- Payload flat v1
- Replay do outbox n√£o altera eventId/occurredAt
- Nenhuma modifica√ß√£o em domain.model.*
8) Pequenas dicas pra evitar dor (do seu c√≥digo atual)
1. N√£o use msg.getEventType() como topic nunca mais
   Isso foi o maior ‚Äúbug sem√¢ntico‚Äù do teu relay.
2. createdAt = Instant.now() no entity: ok.
   Mas occurredAt deve ser sempre o do evento.
   ‚úÖ
   header garante idempot√™ncia nos consumidores ‚úÖ
. 




------------------------------------------------------------------------------------------------------------------
RESULTADO DA TAREFA:

‚Ä¢ Changes

- Outbox records now persist topic and serialized headers alongside payload to replay exactly what will hit Kafka (ms-order/src/main/java/com/mvbr/
  retailstore/order/infrastructure/adapter/out/messaging/outbox/OutboxMessageJpaEntity.java).
- Added flat integration DTO/mapper and header helpers to build the official contract once from the domain event and MDC context (ms-order/src/
  main/java/com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/dto/OrderPlacedEventV1.java, .../mapper/
  OrderPlacedEventMapper.java, .../headers/{HeaderNames,SagaHeaders}.java).
- Outbox publisher now maps OrderPlacedEvent to the flat payload, writes standardized headers, separates logical eventType from Kafka topic, and
  still supports other events (ms-order/src/main/java/com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/outbox/
  OutboxEventPublisherAdapter.java).
- Relay publishes using the stored topic/key/payload and rehydrates headers from the outbox JSON instead of regenerating them (ms-order/src/main/
  java/com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/outbox/OutboxRelay.java).
- Tests updated/added for the new contract: mapper, headers builder, relay publishing, and adjusted outbox expectations (ms-order/src/test/java/
  com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/...).

Tests

- ./mvnw -q -Dtest=OrderPlacedEventMapperTest,SagaHeadersTest,OutboxRelayTest test




------------------------------------------------------------------------------------------------------------------
ERRO:

as mensagens de eventos de: order.confirmed e order.canceled   .... nao estao saido de forma flat igual a order.placed a seguir:  {
"eventId": "8f62491e-1efd-48f3-9e1c-b88d6585bac7",
"occurredAt": "2025-12-19T21:24:39.342376083Z",
"orderId": {
"value": "6d815396-c4f7-4df4-8793-b3af42a398ae"
},
"customerId": {
"value": "CUST-039"
}
}                ...   para order.confirmed e order.canceled, voce esta expondo dominio.... objeto complexo... e isto pode dar problema no futuro
para os outros microservi√ßos....  e desta forma tamb√©m √© mais dificil para trabalhar nos consumidores.....   sendo assim, fa√ßa: exponha dto
simples flat     como foi feito em order.placed......   nao mude os headers e nem a chave, pois estes dois estao lindos e perfeitos...




------------------------------------------------------------------------------------------------------------------
RESULTADO:

Outbox publisher now maps order.confirmed and order.canceled to flat DTOs (eventId, occurredAt, orderId, customerId) just like placed, keeping
the same key and headers (ms-order/src/main/java/com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/outbox/
OutboxEventPublisherAdapter.java plus new DTO/mapper classes in .../messaging/dto/ and .../messaging/mapper/).
- Added mapper tests for confirmed/canceled and tightened outbox integration checks to ensure payloads are flat and free of VO wrappers (ms-order/
  src/test/java/com/mvbr/retailstore/order/infrastructure/adapter/out/messaging/mapper/*.java, ms-order/src/test/java/com/mvbr/retailstore/order/
  infrastructure/adapter/out/messaging/outbox/OutboxIntegrationTest.java).
- Existing relay and header handling stay as-is; payloads for all three events now serialize flat so consumers don‚Äôt see domain objects.

Tests run: ./mvnw -q -Dtest=OrderPlacedEventMapperTest,OrderConfirmedEventMapperTest,OrderCanceledEventMapperTest,SagaHeadersTest,OutboxRelayTest
test (did not run DB-backed integration tests).














